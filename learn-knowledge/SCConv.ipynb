{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5572c57",
   "metadata": {},
   "source": [
    "论文复现代码：https://github.com/cheng-haha/ScConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b7bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # 导入 PyTorch 库\n",
    "import torch.nn.functional as F  # 导入 PyTorch 的函数库\n",
    "import torch.nn as nn  # 导入 PyTorch 的神经网络模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac26d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 GroupBatchnorm2d 类，实现分组批量归一化\n",
    "class GroupBatchnorm2d(nn.Module):\n",
    "    def __init__(self, c_num:int, group_num:int = 16, eps:float = 1e-10):\n",
    "        super(GroupBatchnorm2d,self).__init__()  # 调用父类构造函数\n",
    "        assert c_num >= group_num  # 断言 c_num 大于等于 group_num\n",
    "        self.group_num  = group_num  # 设置分组数量\n",
    "        self.gamma      = nn.Parameter(torch.randn(c_num, 1, 1))  # 创建可训练参数 gamma\n",
    "        self.beta       = nn.Parameter(torch.zeros(c_num, 1, 1))  # 创建可训练参数 beta\n",
    "        self.eps        = eps  # 设置小的常数 eps 用于稳定计算\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W  = x.size()  # 获取输入张量的尺寸\n",
    "        x           = x.view(N, self.group_num, -1)  # 将输入张量重新排列为指定的形状\n",
    "        mean        = x.mean(dim=2, keepdim=True)  # 计算每个组的均值\n",
    "        std         = x.std(dim=2, keepdim=True)  # 计算每个组的标准差\n",
    "        x           = (x - mean) / (std + self.eps)  # 应用批量归一化\n",
    "        x           = x.view(N, C, H, W)  # 恢复原始形状\n",
    "        return x * self.gamma + self.beta  # 返回归一化后的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b85b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 SRU（Spatial and Reconstruct Unit）类\n",
    "class SRU(nn.Module):\n",
    "    def __init__(self,\n",
    "                 oup_channels:int,  # 输出通道数\n",
    "                 group_num:int = 16,  # 分组数，默认为16\n",
    "                 gate_treshold:float = 0.5,  # 门控阈值，默认为0.5\n",
    "                 torch_gn:bool = False  # 是否使用PyTorch内置的GroupNorm，默认为False\n",
    "                 ):\n",
    "        super().__init__()  # 调用父类构造函数\n",
    "\n",
    "         # 初始化 GroupNorm 层或自定义 GroupBatchnorm2d 层\n",
    "        self.gn = nn.GroupNorm(num_channels=oup_channels, num_groups=group_num) if torch_gn else GroupBatchnorm2d(c_num=oup_channels, group_num=group_num)\n",
    "        self.gate_treshold  = gate_treshold  # 设置门控阈值\n",
    "        self.sigomid        = nn.Sigmoid()  # 创建 sigmoid 激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        gn_x        = self.gn(x)  # 应用分组批量归一化\n",
    "        w_gamma     = self.gn.gamma / sum(self.gn.gamma)  # 计算 gamma 权重\n",
    "        reweights   = self.sigomid(gn_x * w_gamma)  # 计算重要性权重\n",
    "\n",
    "        # 门控机制\n",
    "        info_mask    = reweights >= self.gate_treshold  # 计算信息门控掩码\n",
    "        noninfo_mask = reweights < self.gate_treshold  # 计算非信息门控掩码\n",
    "        x_1          = info_mask * x  # 使用信息门控掩码\n",
    "        x_2          = noninfo_mask * x  # 使用非信息门控掩码\n",
    "        x            = self.reconstruct(x_1, x_2)  # 重构特征\n",
    "        return x\n",
    "\n",
    "    def reconstruct(self, x_1, x_2):\n",
    "        x_11, x_12 = torch.split(x_1, x_1.size(1) // 2, dim=1)  # 拆分特征为两部分\n",
    "        x_21, x_22 = torch.split(x_2, x_2.size(1) // 2, dim=1)  # 拆分特征为两部分\n",
    "        return torch.cat([x_11 + x_22, x_12 + x_21], dim=1)  # 重构特征并连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641fc2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 CRU（Channel Reduction Unit）类\n",
    "class CRU(nn.Module):\n",
    "    def __init__(self, op_channel:int, alpha:float = 1/2, squeeze_radio:int = 2, group_size:int = 2, group_kernel_size:int = 3):\n",
    "        super().__init__()  # 调用父类构造函数\n",
    "\n",
    "        self.up_channel     = up_channel = int(alpha * op_channel)  # 计算上层通道数\n",
    "        self.low_channel    = low_channel = op_channel - up_channel  # 计算下层通道数\n",
    "        self.squeeze1       = nn.Conv2d(up_channel, up_channel // squeeze_radio, kernel_size=1, bias=False)  # 创建卷积层\n",
    "        self.squeeze2       = nn.Conv2d(low_channel, low_channel // squeeze_radio, kernel_size=1, bias=False)  # 创建卷积层\n",
    "\n",
    "        # 上层特征转换\n",
    "        self.GWC            = nn.Conv2d(up_channel // squeeze_radio, op_channel, kernel_size=group_kernel_size, stride=1, padding=group_kernel_size // 2, groups=group_size)  # 创建卷积层\n",
    "        self.PWC1           = nn.Conv2d(up_channel // squeeze_radio, op_channel, kernel_size=1, bias=False)  # 创建卷积层\n",
    "\n",
    "        # 下层特征转换\n",
    "        self.PWC2           = nn.Conv2d(low_channel // squeeze_radio, op_channel - low_channel // squeeze_radio, kernel_size=1, bias=False)  # 创建卷积层\n",
    "        self.advavg         = nn.AdaptiveAvgPool2d(1)  # 创建自适应平均池化层\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 分割输入特征\n",
    "        up, low = torch.split(x, [self.up_channel, self.low_channel], dim=1)\n",
    "        up, low = self.squeeze1(up), self.squeeze2(low)\n",
    "\n",
    "        # 上层特征转换\n",
    "        Y1 = self.GWC(up) + self.PWC1(up)\n",
    "\n",
    "        # 下层特征转换\n",
    "        Y2 = torch.cat([self.PWC2(low), low], dim=1)\n",
    "\n",
    "        # 特征融合\n",
    "        out = torch.cat([Y1, Y2], dim=1)\n",
    "        out = F.softmax(self.advavg(out), dim=1) * out\n",
    "        out1, out2 = torch.split(out, out.size(1) // 2, dim=1)\n",
    "        return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41418a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# 自定义 ScConv（Squeeze and Channel Reduction Convolution）模型\n",
    "class ScConv(nn.Module):\n",
    "    def __init__(self, op_channel:int, group_num:int = 16, gate_treshold:float = 0.5, alpha:float = 1/2, squeeze_radio:int = 2, group_size:int = 2, group_kernel_size:int = 3):\n",
    "        super().__init__()  # 调用父类构造函数\n",
    "\n",
    "        self.SRU = SRU(op_channel, group_num=group_num, gate_treshold=gate_treshold)  # 创建 SRU 层\n",
    "        self.CRU = CRU(op_channel, alpha=alpha, squeeze_radio=squeeze_radio, group_size=group_size, group_kernel_size=group_kernel_size)  # 创建 CRU 层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.SRU(x)  # 应用 SRU 层\n",
    "        x = self.CRU(x)  # 应用 CRU 层\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x       = torch.randn(1, 32, 16, 16)  # 创建随机输入张量\n",
    "    model   = ScConv(32)  # 创建 ScConv 模型\n",
    "    print(model(x).shape)  # 打印模型输出的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67568553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
