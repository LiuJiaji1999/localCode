{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5a75e4",
   "metadata": {},
   "source": [
    "# 神经网络架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0f74f",
   "metadata": {},
   "source": [
    "## AlexNet  (63.3% - 2012) \n",
    "成就：\n",
    "  第一个在ImageNet上跑起来的神经网络，在当年的竞赛中成绩大幅度领先第二名。\n",
    "创新：\n",
    "1. 2张GTX580 3G显存上训练百万级别的数据，在模型训练上做了一些工程的改进，现在单张A100显存能到80G，足以见当年的艰难。\n",
    "2. 使用大卷积（11x11、5x5）和 全连接层，事实证明潮流是一个cycle，现在大卷积又开始流行起来了= =。\n",
    "3. RELU：非线性激活单元，直到现在依然很流。\n",
    "4. Dropout：防止过拟合，有模型ensemble的效果，后续应用广泛。\n",
    "5. Local Response Normalization：一种正则化方法帮助模型更好的训练，后续基本没人用，大家可以阅读原文了解下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int = 1000) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65700cb",
   "metadata": {},
   "source": [
    "##  VGG  (74.5% - 2014) \n",
    "成就： \n",
    "  ImageNet成绩大幅超过AlexNet，引领了未来网络朝着深度加深的方向进行。\n",
    "创新： \n",
    "1. 使用3X3卷积核代替11X11, 5X5，将网络的深度做进一步加深的同时引入更多的非线性层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    \"vgg11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"vgg13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"vgg16\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "    \"vgg19\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name, num_outputs=10):\n",
    "        super().__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [\n",
    "                    nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                ]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f62a9b",
   "metadata": {},
   "source": [
    "##  ResNet (78.6% - 2015)\n",
    "成就： \n",
    "  利用残差结构使得网络达到了前所未有的深度同时性能继续提升、同时使损失函数平面更加光滑\n",
    "创新： \n",
    "1. 残差网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # print(f\"in_planes : {in_planes} | self.expansion * out_planes : {self.expansion * out_planes}\")\n",
    "        if stride != 1 or in_planes != self.expansion * out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(f\"  conv 1: {out.shape}\")\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # print(f\"  conv 2: {out.shape}\")\n",
    "        out += self.shortcut(x)  #! key  关键代码就这一行！！！！！！！\n",
    "        # print(f\"shortcut: {out.shape}\")\n",
    "        out = F.relu(out)  # 然后一起relu\n",
    "        # print(\"===\" * 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea6372",
   "metadata": {},
   "source": [
    "##  Inception (80.0% - 2016)  GoogLeNet\n",
    "创新：\n",
    "1. 使用多尺度卷积核来提取信息，V1-V4基本就是在做这件事，无非是不断的优化性能。\n",
    "2. 提出了Label Smoothing，这个东西比赛用的挺多的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fdd0d",
   "metadata": {},
   "source": [
    "## DenseNet (77.8% - 2016) \n",
    "创新：\n",
    "1. 利用DenseBlock进行新特征的探索和原始特征的多次重用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, 4 * growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat([out, x], 1) #! key\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a31600",
   "metadata": {},
   "source": [
    "## ResNext (80.9% - 2016) \n",
    "创新：\n",
    "1. 提出Group的概念、利用Group增加特征的丰富度和多样性，类似multi-head attention。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a14b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Grouped convolution block.\"\"\"\n",
    "\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, in_planes, cardinality=32, bottleneck_width=4, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        group_width = cardinality * bottleneck_width\n",
    "        self.conv1 = nn.Conv2d(in_planes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(group_width)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            group_width, group_width, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False\n",
    "        )  #! key\n",
    "        self.bn2 = nn.BatchNorm2d(group_width)\n",
    "        self.conv3 = nn.Conv2d(group_width, self.expansion * group_width, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * group_width)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * group_width:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * group_width, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * group_width),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a5839",
   "metadata": {},
   "source": [
    "## Res2Net (81.2% - 2016) \n",
    "亮点：\n",
    "1. 将多特征图的处理从layer并行的形势改为hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为修改了特征图的交互为hierarchical，所以代码有点多\n",
    "class Bottle2neck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, baseWidth=26, scale=4, stype=\"normal\"):\n",
    "        \"\"\"Constructor\n",
    "        Args:\n",
    "            inplanes: input channel dimensionality\n",
    "            planes: output channel dimensionality\n",
    "            stride: conv stride. Replaces pooling layer.\n",
    "            downsample: None when stride = 1\n",
    "            baseWidth: basic width of conv3x3\n",
    "            scale: number of scale.\n",
    "            type: 'normal': normal set. '': first block of a new .\n",
    "        \"\"\"\n",
    "        super(Bottle2neck, self).__init__()\n",
    "        # todo baseWidth, width, scale的含义\n",
    "        width = int(math.floor(planes * (baseWidth / 64.0)))\n",
    "        print(f\"width : {width}\")\n",
    "        self.conv1 = nn.Conv2d(inplanes, width * scale, kernel_size=1, bias=False)\n",
    "        print(f\"width * scale : {width * scale}\")\n",
    "        self.bn1 = nn.BatchNorm2d(width * scale)\n",
    "\n",
    "        # nums的含义\n",
    "        if scale == 1:\n",
    "            self.nums = 1\n",
    "        else:\n",
    "            self.nums = scale - 1\n",
    "            \n",
    "        # todo stype的含义\n",
    "        if stype == \"\":\n",
    "            self.pool = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "\n",
    "        # 这里似乎是核心改进点\n",
    "        convs = []\n",
    "        bns = []\n",
    "        for i in range(self.nums):\n",
    "            convs.append(nn.Conv2d(width, width, kernel_size=3, stride=stride, padding=1, bias=False))\n",
    "            bns.append(nn.BatchNorm2d(width))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.bns = nn.ModuleList(bns)\n",
    "        print(f\"convs : {len(convs)}\")\n",
    "        self.conv3 = nn.Conv2d(width * scale, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stype = stype\n",
    "        self.scale = scale\n",
    "        self.width = width\n",
    "        print(\"============= init finish =============\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        print(f\"x : {x.shape}\")\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        print(f\"conv1 : {out.shape}\")        \n",
    "\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in spx:\n",
    "            print(i.shape)\n",
    "        print(f\"len(spx) : {len(spx)}\")\n",
    "        for i in range(self.nums):\n",
    "            if i == 0 or self.stype == \"\":\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            \n",
    "            print(f\"sp : {sp.shape}\")\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.relu(self.bns[i](sp))\n",
    "            if i == 0:\n",
    "                out = sp\n",
    "            else:\n",
    "                out = torch.cat((out, sp), 1) # 相当于y2-y3-y4\n",
    "        if self.scale != 1 and self.stype == \"normal\":\n",
    "            out = torch.cat((out, spx[self.nums]), 1) # 相当于y1的部分\n",
    "        elif self.scale != 1 and self.stype == \"\":\n",
    "            out = torch.cat((out, self.pool(spx[self.nums])), 1)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9f47d",
   "metadata": {},
   "source": [
    "##  SENet (81.3% - 2017) \n",
    "创新：\n",
    "1. 提出SELayer、利用可插拔的SELayer调节不同Channel的重要性，和Attention效果类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)  # 将(b,c,1,1)转换为(b,c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)  # 将(b,c)转换为(b,c,1,1), 方便做attention\n",
    "        return x * y.expand_as(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470fb35c",
   "metadata": {},
   "source": [
    "## DPN (80.1% - 2017) \n",
    "创新：\n",
    "1. 将resnet和densenet的思想做了结合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c6448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPNBottleneck(nn.Module):\n",
    "    def __init__(self, last_planes, in_planes, out_planes, dense_depth, stride, first_layer):\n",
    "        super(DPNBottleneck, self).__init__()\n",
    "        self.out_planes = out_planes\n",
    "        self.dense_depth = dense_depth\n",
    "\n",
    "        self.conv1 = nn.Conv2d(last_planes, in_planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv3 = nn.Conv2d(in_planes, out_planes + dense_depth, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes + dense_depth)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if first_layer:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(last_planes, out_planes + dense_depth, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes + dense_depth),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        x = self.shortcut(x)\n",
    "        d = self.out_planes\n",
    "        out = torch.cat(\n",
    "            [x[:, :d, :, :] + out[:, :d, :, :], x[:, d:, :, :], out[:, d:, :, :]], 1\n",
    "        )  #! key  关键代码！！！   + is residual, cat is dense\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962fb65a",
   "metadata": {},
   "source": [
    "##  DLA (78.0% - 2019)\n",
    "创新： \n",
    "1. 采用IDA和HDA两种结构来进一步提炼conv的表达"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51168f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DLA in PyTorch.\n",
    "Reference:\n",
    "    Deep Layer Aggregation. https://arxiv.org/abs/1707.06484\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# dla相当于只有HDA + IDA\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Root(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1):\n",
    "        super(Root, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, stride=1, padding=(kernel_size - 1) // 2, bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        x = torch.cat(xs, 1)\n",
    "        out = F.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Tree(nn.Module):\n",
    "    def __init__(self, block, in_channels, out_channels, level=1, stride=1):\n",
    "        super(Tree, self).__init__()\n",
    "        self.level = level\n",
    "        if level == 1:\n",
    "            self.root = Root(2 * out_channels, out_channels)\n",
    "            self.left_node = block(in_channels, out_channels, stride=stride)\n",
    "            self.right_node = block(out_channels, out_channels, stride=1)\n",
    "        else:\n",
    "            self.root = Root((level + 2) * out_channels, out_channels)\n",
    "            for i in reversed(range(1, level)):\n",
    "                subtree = Tree(block, in_channels, out_channels, level=i, stride=stride)\n",
    "                self.__setattr__(\"level_%d\" % i, subtree)\n",
    "            self.prev_root = block(in_channels, out_channels, stride=stride)\n",
    "            self.left_node = block(out_channels, out_channels, stride=1)\n",
    "            self.right_node = block(out_channels, out_channels, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = [self.prev_root(x)] if self.level > 1 else []\n",
    "        for i in reversed(range(1, self.level)):\n",
    "            level_i = self.__getattr__(\"level_%d\" % i)\n",
    "            x = level_i(x)\n",
    "            xs.append(x)\n",
    "        x = self.left_node(x)\n",
    "        xs.append(x)\n",
    "        x = self.right_node(x)\n",
    "        xs.append(x)\n",
    "        out = self.root(xs)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DLA(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, num_classes=10):\n",
    "        super(DLA, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False), nn.BatchNorm2d(16), nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False), nn.BatchNorm2d(16), nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False), nn.BatchNorm2d(32), nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer3 = Tree(block, 32, 64, level=1, stride=1)\n",
    "        self.layer4 = Tree(block, 64, 128, level=2, stride=2)\n",
    "        self.layer5 = Tree(block, 128, 256, level=2, stride=2)\n",
    "        self.layer6 = Tree(block, 256, 512, level=1, stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = DLA()\n",
    "    print(net)\n",
    "    x = torch.randn(1, 3, 32, 32)\n",
    "    y = net(x)\n",
    "    print(y.size())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa56544",
   "metadata": {},
   "source": [
    "## EfficientNet v1 v2  (86.8% - 2021) \n",
    "创新：是AutoDL在深度学习上一次非常成功的尝试\n",
    "1. EfficientNet V1 uniformly scales all three dimensions(width, depth, resolution) with a fixed ratio。\n",
    "2. EfficientNet V1 加入一些新block，扩大了搜索空间，并且不是equally scaling up every 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0\n",
    "model = efficientnet_b0()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
